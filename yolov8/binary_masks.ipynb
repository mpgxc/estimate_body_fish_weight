{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bee6fb94-66c8-4968-b471-3b4ceea3f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import filters, img_as_ubyte\n",
    "from skimage.io import imread, imsave, imread_collection\n",
    "from skimage.transform import resize\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ccf50-03a8-45f7-ace7-1f3a815444d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d05a3f2-bac4-41ee-95ba-f7a53d4a7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing_mask_edges(mask):\n",
    "    tmp = filters.gaussian(mask, sigma=3)\n",
    "    return tmp > filters.threshold_otsu(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5214bfad-429d-40fb-8045-e674eb239ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_models(image):\n",
    "    \n",
    "    paths = [\n",
    "        'yolov8x-seg.pt',\n",
    "        'yolov8l-seg.pt',\n",
    "        'yolov8m-seg.pt',\n",
    "        'yolov8s-seg.pt',\n",
    "        'yolov8n-seg.pt',\n",
    "    ]\n",
    "    \n",
    "    for model_path in paths:\n",
    "        \n",
    "        try:\n",
    "            model = YOLO(\"models/\" + model_path)\n",
    "\n",
    "            preds, *_ = model.predict(source=image)\n",
    "            \n",
    "            return preds.masks.masks\n",
    "        except:\n",
    "            print(\"Model Error: \", model_path)\n",
    "            continue\n",
    "    return ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "854881af-0d7b-4159-a97c-8f2726e8f47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 airplane, 497.2ms\n",
      "Speed: 0.3ms preprocess, 497.2ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "1it [00:02,  2.10s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 bear, 489.0ms\n",
      "Speed: 0.2ms preprocess, 489.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "2it [00:04,  2.09s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 (no detections), 524.6ms\n",
      "Speed: 0.4ms preprocess, 524.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Error:  yolov8x-seg.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l-seg summary (fused): 295 layers, 45973568 parameters, 0 gradients, 220.5 GFLOPs\n",
      "\n",
      "0: 512x640 1 person, 1 umbrella, 333.8ms\n",
      "Speed: 0.3ms preprocess, 333.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "3it [00:07,  2.50s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 bear, 492.0ms\n",
      "Speed: 0.3ms preprocess, 492.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "4it [00:09,  2.37s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 2 bears, 521.2ms\n",
      "Speed: 0.4ms preprocess, 521.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "5it [00:11,  2.35s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 2 birds, 493.5ms\n",
      "Speed: 0.3ms preprocess, 493.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "6it [00:13,  2.26s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 bird, 1 dog, 516.7ms\n",
      "Speed: 0.4ms preprocess, 516.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "7it [00:15,  2.22s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 bird, 1 banana, 491.5ms\n",
      "Speed: 0.3ms preprocess, 491.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "8it [00:18,  2.20s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 bird, 1 bear, 497.8ms\n",
      "Speed: 0.4ms preprocess, 497.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "9it [00:20,  2.20s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 2 birds, 529.9ms\n",
      "Speed: 0.3ms preprocess, 529.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "10it [00:22,  2.23s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 bird, 499.8ms\n",
      "Speed: 0.3ms preprocess, 499.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "11it [00:24,  2.24s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 bird, 484.3ms\n",
      "Speed: 0.2ms preprocess, 484.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "12it [00:26,  2.20s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 dog, 513.5ms\n",
      "Speed: 0.4ms preprocess, 513.5ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "13it [00:29,  2.18s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 bird, 488.3ms\n",
      "Speed: 0.3ms preprocess, 488.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "14it [00:31,  2.17s/it]Ultralytics YOLOv8.0.43 ðŸš€ Python-3.9.13 torch-1.13.1+cu117 CPU\n",
      "YOLOv8x-seg summary (fused): 295 layers, 71797696 parameters, 0 gradients, 344.1 GFLOPs\n",
      "\n",
      "0: 512x640 1 bird, 521.2ms\n",
      "Speed: 0.3ms preprocess, 521.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "15it [00:33,  2.22s/it]\n"
     ]
    }
   ],
   "source": [
    "for index, frame in tqdm(enumerate(imread_collection(\"images/*\")[:15])):\n",
    "    \n",
    "    height, width, channels = frame.shape\n",
    "    \n",
    "    result = np.ones((512, 640))\n",
    "    \n",
    "    for mask in try_all_models(frame): result += np.asarray(mask)\n",
    "    \n",
    "    mask_resized = resize(result, (height, width), anti_aliasing=True)\n",
    "    \n",
    "    mask_smoothed = smoothing_mask_edges(mask_resized)\n",
    "    \n",
    "    imsave(f\"output/{index}.png\", img_as_ubyte(mask_smoothed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018f395-b2e0-4571-9790-e07f49a717b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
